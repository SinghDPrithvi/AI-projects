{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3f9b70-bda2-4ccd-8c9c-dfeae8f949dd",
   "metadata": {},
   "source": [
    "# 0. import dependcies of what we will be using \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18d2c06-9596-4fb2-be03-ad2ded425ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3\n",
      "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-install-noe38cuc/stable-baselines3_5106c8d5f0484465abf7516ac3759dac\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-install-noe38cuc/stable-baselines3_5106c8d5f0484465abf7516ac3759dac\n",
      "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit f4ec0f6afa1a23b0e0b746174cd0074471cc0b89\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.13 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.0.1)\n",
      "Requirement already satisfied: cloudpickle in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.7.2)\n",
      "Collecting sphinx<7.0,>=5.3 (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx-6.2.1-py3-none-any.whl (3.0 MB)\n",
      "Collecting sphinx-autobuild (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx_autobuild-2021.3.14-py3-none-any.whl (9.9 kB)\n",
      "Collecting sphinx-rtd-theme (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx_rtd_theme-1.2.2-py2.py3-none-any.whl (2.8 MB)\n",
      "Collecting sphinxcontrib.spelling (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinxcontrib_spelling-8.0.0-py3-none-any.whl (16 kB)\n",
      "Collecting sphinx-autodoc-typehints (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx_autodoc_typehints-1.24.0-py3-none-any.whl (17 kB)\n",
      "Collecting sphinx-copybutton (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx_copybutton-0.5.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: opencv-python in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.8.0.76)\n",
      "Requirement already satisfied: pygame in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.1.3)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.13.0)\n",
      "Requirement already satisfied: psutil in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (5.9.5)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.66.1)\n",
      "Requirement already satisfied: rich in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (13.5.2)\n",
      "Collecting shimmy[atari]~=1.1.0 (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pillow in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (10.0.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.6.1)\n",
      "Collecting pytest (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pytest-7.4.0-py3-none-any.whl (323 kB)\n",
      "Collecting pytest-cov (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pytest_cov-4.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting pytest-env (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pytest_env-0.8.2-py3-none-any.whl (5.3 kB)\n",
      "Collecting pytest-xdist (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pytest_xdist-3.3.1-py3-none-any.whl (41 kB)\n",
      "Collecting pytype (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Downloading pytype-2023.8.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting mypy (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Downloading mypy-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting ruff (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Downloading ruff-0.0.285-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: isort>=5.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (5.12.0)\n",
      "Requirement already satisfied: black in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (23.7.0)\n",
      "Requirement already satisfied: click in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (8.1.4)\n",
      "Requirement already satisfied: requests in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.31.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from shimmy[atari]~=1.1.0->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.8.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.13 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.15.1)\n",
      "Collecting docutils<0.20,>=0.18.1 (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached docutils-0.19-py3-none-any.whl (570 kB)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.12.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (23.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.57.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.4.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.3.7)\n",
      "Requirement already satisfied: wheel>=0.26 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.40.0)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.0.0)\n",
      "Requirement already satisfied: cmake in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.27.2)\n",
      "Requirement already satisfied: lit in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (16.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from black->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from black->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.11.1)\n",
      "Requirement already satisfied: platformdirs>=2 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from black->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.8.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from black->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from matplotlib->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pandas->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pandas->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2023.3)\n",
      "Collecting iniconfig (from pytest->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pytest->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pytest->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.1.3)\n",
      "Collecting coverage[toml]>=5.2.1 (from pytest-cov->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Downloading coverage-7.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.0/229.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting execnet>=1.1 (from pytest-xdist->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached execnet-2.0.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: attrs>=21.4.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (23.1.0)\n",
      "Collecting importlab>=0.8 (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached importlab-0.8-py2.py3-none-any.whl (21 kB)\n",
      "Collecting libcst>=1.0.1 (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached libcst-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "Collecting ninja>=1.10.0.post2 (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Collecting pydot>=1.4.2 (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting tabulate>=0.8.10 (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: toml>=0.10.2 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.10.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from rich->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.0.0)\n",
      "Collecting livereload (from sphinx-autobuild->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached livereload-2.6.3-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: colorama in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sphinx-autobuild->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.4.6)\n",
      "INFO: pip is looking at multiple versions of sphinx-autodoc-typehints to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sphinx-autodoc-typehints (from stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinx_autodoc_typehints-1.23.3-py3-none-any.whl (18 kB)\n",
      "  Using cached sphinx_autodoc_typehints-1.23.2-py3-none-any.whl (18 kB)\n",
      "  Using cached sphinx_autodoc_typehints-1.23.1-py3-none-any.whl (18 kB)\n",
      "  Using cached sphinx_autodoc_typehints-1.23.0-py3-none-any.whl (17 kB)\n",
      "Collecting docutils<0.20,>=0.18.1 (from sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Collecting PyEnchant>=3.1.1 (from sphinxcontrib.spelling->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: importlib-resources in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.1.0->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (6.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from Jinja2>=3.0->sphinx<7.0,>=5.3->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2.1.3)\n",
      "Collecting typing-inspect>=0.4.0 (from libcst>=1.0.1->pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.2 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from libcst>=1.0.1->pytype->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (6.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (2023.7.22)\n",
      "Requirement already satisfied: tornado in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from livereload->sphinx-autobuild->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (6.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from sympy->torch>=1.13->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/envs/spyder-env/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable_baselines3[docs,extra,tests]@ git+https://github.com/DLR-RM/stable-baselines3) (3.2.2)\n",
      "Building wheels for collected packages: stable_baselines3\n",
      "  Building wheel for stable_baselines3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stable_baselines3: filename=stable_baselines3-2.1.0-py3-none-any.whl size=178734 sha256=0f6e648896a974434955994fe4f331e86b2b56d9fa26de75b2c238c3b702f895\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_et8g1jj/wheels/3b/24/65/bc2794face336930a72bdbe36faf5aad6e2352b3d1dec310ca\n",
      "Successfully built stable_baselines3\n",
      "Installing collected packages: ninja, typing-inspect, tabulate, ruff, PyEnchant, pydot, mypy, livereload, iniconfig, importlab, gymnasium, execnet, docutils, coverage, sphinx, shimmy, pytest, libcst, sphinxcontrib.spelling, sphinxcontrib-jquery, sphinx-copybutton, sphinx-autodoc-typehints, sphinx-autobuild, pytype, pytest-xdist, pytest-env, pytest-cov, sphinx-rtd-theme, stable_baselines3\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: Gymnasium 0.26.3\n",
      "    Uninstalling Gymnasium-0.26.3:\n",
      "      Successfully uninstalled Gymnasium-0.26.3\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.20.1\n",
      "    Uninstalling docutils-0.20.1:\n",
      "      Successfully uninstalled docutils-0.20.1\n",
      "  Attempting uninstall: sphinx\n",
      "    Found existing installation: Sphinx 7.0.1\n",
      "    Uninstalling Sphinx-7.0.1:\n",
      "      Successfully uninstalled Sphinx-7.0.1\n",
      "  Attempting uninstall: shimmy\n",
      "    Found existing installation: Shimmy 0.2.1\n",
      "    Uninstalling Shimmy-0.2.1:\n",
      "      Successfully uninstalled Shimmy-0.2.1\n",
      "  Attempting uninstall: stable_baselines3\n",
      "    Found existing installation: stable-baselines3 2.0.0\n",
      "    Uninstalling stable-baselines3-2.0.0:\n",
      "      Successfully uninstalled stable-baselines3-2.0.0\n",
      "Successfully installed PyEnchant-3.2.2 coverage-7.3.0 docutils-0.18.1 execnet-2.0.2 gymnasium-0.29.0 importlab-0.8 iniconfig-2.0.0 libcst-1.0.1 livereload-2.6.3 mypy-1.5.1 ninja-1.11.1 pydot-1.4.2 pytest-7.4.0 pytest-cov-4.1.0 pytest-env-0.8.2 pytest-xdist-3.3.1 pytype-2023.8.14 ruff-0.0.285 shimmy-1.1.0 sphinx-6.2.1 sphinx-autobuild-2021.3.14 sphinx-autodoc-typehints-1.23.0 sphinx-copybutton-0.5.2 sphinx-rtd-theme-1.2.2 sphinxcontrib-jquery-4.1 sphinxcontrib.spelling-8.0.0 stable_baselines3-2.1.0 tabulate-0.9.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"stable_baselines3[extra,tests,docs] @ git+https://github.com/DLR-RM/stable-baselines3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d3161c-b597-414d-a15a-0b259085ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "from stable_baselines3 import DQN \n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy  \n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold \n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36c0ea-e0e0-41a5-8ece-3d93bfa9a5bf",
   "metadata": {},
   "source": [
    "# 1. Making The Enviornment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef5eed5-a8de-4903-bea3-2a6c4077fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\",render_mode = 'human') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5fc3e-0f25-4bff-a7ab-036b9eb6d549",
   "metadata": {},
   "source": [
    "# 2. Designating a Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5add6bcf-dfe8-4b34-ba4a-34ad30ac0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN_path = os.path.join('RL','Model')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382ffdb-6ba8-4606-b740-14aabeca9636",
   "metadata": {},
   "source": [
    "# 3. Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89d6d7c-5bce-42ad-bf24-9e548478fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoptraining = StopTrainingOnRewardThreshold(reward_threshold=200,verbose=1) \n",
    "evalcallback = EvalCallback(env,callback_on_new_best = stoptraining,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422da266-f379-4fef-89d8-7e05c7c177e1",
   "metadata": {},
   "source": [
    "# 4. Applying Wrappers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8125527a-94f8-4a0f-b17a-706daa10311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: gym.make(\"LunarLander-v2\", render_mode = 'human')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeba82b-bdd4-44eb-849c-b6d2ffcf68b8",
   "metadata": {},
   "source": [
    "# 5. Training Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9daf0bcd-1bb2-4407-af7e-8f8c1cb238a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 321      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 632      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 1045     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 1428     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 1830     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 2177     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 2490     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 2911     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 3247     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 3590     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 3964     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 4363     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 4731     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 5092     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 5518     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 5895     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 6175     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 6563     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 6944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 8321     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 8649     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 9062     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 9384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 9748     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prithvisingh/anaconda3/envs/spyder-env/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-148.89 +/- 22.66\n",
      "Episode length: 74.60 +/- 13.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 74.6     |\n",
      "|    mean_reward      | -149     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 10110    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 10502    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 10867    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 11280    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 11699    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 12034    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 12449    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 12824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 13179    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 13600    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 14030    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 14374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 14689    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 15072    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 15432    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 15752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 16106    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 16435    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 16823    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 17126    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 369      |\n",
      "|    total_timesteps  | 17500    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total_timesteps  | 17956    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 386      |\n",
      "|    total_timesteps  | 18326    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 394      |\n",
      "|    total_timesteps  | 18747    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total_timesteps  | 19117    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 19503    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 417      |\n",
      "|    total_timesteps  | 19850    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-99.26 +/- 62.78\n",
      "Episode length: 69.80 +/- 11.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 69.8     |\n",
      "|    mean_reward      | -99.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total_timesteps  | 20136    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 438      |\n",
      "|    total_timesteps  | 20496    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 446      |\n",
      "|    total_timesteps  | 20892    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 454      |\n",
      "|    total_timesteps  | 21281    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 461      |\n",
      "|    total_timesteps  | 21644    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 471      |\n",
      "|    total_timesteps  | 22095    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 478      |\n",
      "|    total_timesteps  | 22441    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 487      |\n",
      "|    total_timesteps  | 22887    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 494      |\n",
      "|    total_timesteps  | 23229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 503      |\n",
      "|    total_timesteps  | 23671    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 513      |\n",
      "|    total_timesteps  | 24145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 521      |\n",
      "|    total_timesteps  | 24539    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 527      |\n",
      "|    total_timesteps  | 24828    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 534      |\n",
      "|    total_timesteps  | 25147    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 543      |\n",
      "|    total_timesteps  | 25581    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 550      |\n",
      "|    total_timesteps  | 25933    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 557      |\n",
      "|    total_timesteps  | 26273    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 565      |\n",
      "|    total_timesteps  | 26639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 573      |\n",
      "|    total_timesteps  | 27027    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 27329    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 587      |\n",
      "|    total_timesteps  | 27719    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 594      |\n",
      "|    total_timesteps  | 28046    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 600      |\n",
      "|    total_timesteps  | 28342    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 608      |\n",
      "|    total_timesteps  | 28739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 616      |\n",
      "|    total_timesteps  | 29127    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 624      |\n",
      "|    total_timesteps  | 29517    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 631      |\n",
      "|    total_timesteps  | 29870    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-126.64 +/- 32.02\n",
      "Episode length: 64.40 +/- 8.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 64.4     |\n",
      "|    mean_reward      | -127     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 645      |\n",
      "|    total_timesteps  | 30208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 653      |\n",
      "|    total_timesteps  | 30602    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 660      |\n",
      "|    total_timesteps  | 30945    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 668      |\n",
      "|    total_timesteps  | 31315    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 676      |\n",
      "|    total_timesteps  | 31740    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 684      |\n",
      "|    total_timesteps  | 32114    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 690      |\n",
      "|    total_timesteps  | 32395    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 698      |\n",
      "|    total_timesteps  | 32772    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 705      |\n",
      "|    total_timesteps  | 33121    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 712      |\n",
      "|    total_timesteps  | 33452    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 720      |\n",
      "|    total_timesteps  | 33844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 727      |\n",
      "|    total_timesteps  | 34187    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 734      |\n",
      "|    total_timesteps  | 34514    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 741      |\n",
      "|    total_timesteps  | 34853    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 748      |\n",
      "|    total_timesteps  | 35192    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 755      |\n",
      "|    total_timesteps  | 35547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 761      |\n",
      "|    total_timesteps  | 35834    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 768      |\n",
      "|    total_timesteps  | 36165    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 776      |\n",
      "|    total_timesteps  | 36570    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 784      |\n",
      "|    total_timesteps  | 36958    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 791      |\n",
      "|    total_timesteps  | 37322    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 799      |\n",
      "|    total_timesteps  | 37688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 807      |\n",
      "|    total_timesteps  | 38063    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 814      |\n",
      "|    total_timesteps  | 38418    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 822      |\n",
      "|    total_timesteps  | 38781    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 828      |\n",
      "|    total_timesteps  | 39097    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 836      |\n",
      "|    total_timesteps  | 39470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 843      |\n",
      "|    total_timesteps  | 39791    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-117.39 +/- 8.24\n",
      "Episode length: 62.60 +/- 6.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 62.6     |\n",
      "|    mean_reward      | -117     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 857      |\n",
      "|    total_timesteps  | 40183    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 863      |\n",
      "|    total_timesteps  | 40446    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 870      |\n",
      "|    total_timesteps  | 40810    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 877      |\n",
      "|    total_timesteps  | 41146    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 885      |\n",
      "|    total_timesteps  | 41510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 893      |\n",
      "|    total_timesteps  | 41890    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 901      |\n",
      "|    total_timesteps  | 42304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 909      |\n",
      "|    total_timesteps  | 42685    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 915      |\n",
      "|    total_timesteps  | 42981    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 922      |\n",
      "|    total_timesteps  | 43309    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 929      |\n",
      "|    total_timesteps  | 43661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 936      |\n",
      "|    total_timesteps  | 44018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 946      |\n",
      "|    total_timesteps  | 44489    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 953      |\n",
      "|    total_timesteps  | 44832    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 961      |\n",
      "|    total_timesteps  | 45216    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 968      |\n",
      "|    total_timesteps  | 45527    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 975      |\n",
      "|    total_timesteps  | 45874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 983      |\n",
      "|    total_timesteps  | 46284    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 990      |\n",
      "|    total_timesteps  | 46626    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 997      |\n",
      "|    total_timesteps  | 46954    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1004     |\n",
      "|    total_timesteps  | 47283    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1013     |\n",
      "|    total_timesteps  | 47715    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1020     |\n",
      "|    total_timesteps  | 48081    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1028     |\n",
      "|    total_timesteps  | 48447    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1036     |\n",
      "|    total_timesteps  | 48824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1043     |\n",
      "|    total_timesteps  | 49163    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1050     |\n",
      "|    total_timesteps  | 49536    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1057     |\n",
      "|    total_timesteps  | 49891    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-136.64 +/- 47.38\n",
      "Episode length: 69.60 +/- 11.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 69.6     |\n",
      "|    mean_reward      | -137     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1073     |\n",
      "|    total_timesteps  | 50273    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.907    |\n",
      "|    n_updates        | 68       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1082     |\n",
      "|    total_timesteps  | 50745    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.08     |\n",
      "|    n_updates        | 186      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1093     |\n",
      "|    total_timesteps  | 51266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 316      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1106     |\n",
      "|    total_timesteps  | 51890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 472      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1115     |\n",
      "|    total_timesteps  | 52358    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.636    |\n",
      "|    n_updates        | 589      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1124     |\n",
      "|    total_timesteps  | 52782    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.997    |\n",
      "|    n_updates        | 695      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1132     |\n",
      "|    total_timesteps  | 53171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 792      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1140     |\n",
      "|    total_timesteps  | 53573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.938    |\n",
      "|    n_updates        | 893      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1150     |\n",
      "|    total_timesteps  | 54039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 1009     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1158     |\n",
      "|    total_timesteps  | 54427    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 1106     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1170     |\n",
      "|    total_timesteps  | 55056    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.82     |\n",
      "|    n_updates        | 1263     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1181     |\n",
      "|    total_timesteps  | 55581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4        |\n",
      "|    n_updates        | 1395     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1191     |\n",
      "|    total_timesteps  | 56077    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.86     |\n",
      "|    n_updates        | 1519     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1203     |\n",
      "|    total_timesteps  | 56640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41     |\n",
      "|    n_updates        | 1659     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1212     |\n",
      "|    total_timesteps  | 57075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 1768     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1222     |\n",
      "|    total_timesteps  | 57550    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 1887     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1233     |\n",
      "|    total_timesteps  | 58099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 2024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1242     |\n",
      "|    total_timesteps  | 58540    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 2134     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1251     |\n",
      "|    total_timesteps  | 58970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.96     |\n",
      "|    n_updates        | 2242     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1260     |\n",
      "|    total_timesteps  | 59405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.764    |\n",
      "|    n_updates        | 2351     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 59850    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 2462     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-247.66 +/- 24.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -248     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1382     |\n",
      "|    total_timesteps  | 60449    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.948    |\n",
      "|    n_updates        | 2612     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1391     |\n",
      "|    total_timesteps  | 60897    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.47     |\n",
      "|    n_updates        | 2724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1403     |\n",
      "|    total_timesteps  | 61469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 2867     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1415     |\n",
      "|    total_timesteps  | 62070    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.86     |\n",
      "|    n_updates        | 3017     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1426     |\n",
      "|    total_timesteps  | 62580    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.705    |\n",
      "|    n_updates        | 3144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1433     |\n",
      "|    total_timesteps  | 62950    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.52     |\n",
      "|    n_updates        | 3237     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1445     |\n",
      "|    total_timesteps  | 63508    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 3376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1454     |\n",
      "|    total_timesteps  | 63971    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 3492     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1465     |\n",
      "|    total_timesteps  | 64502    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 3625     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1474     |\n",
      "|    total_timesteps  | 64956    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 3738     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1488     |\n",
      "|    total_timesteps  | 65606    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.57     |\n",
      "|    n_updates        | 3901     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1499     |\n",
      "|    total_timesteps  | 66152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 4037     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1512     |\n",
      "|    total_timesteps  | 66803    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.673    |\n",
      "|    n_updates        | 4200     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1524     |\n",
      "|    total_timesteps  | 67359    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 4339     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1533     |\n",
      "|    total_timesteps  | 67836    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 4458     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1544     |\n",
      "|    total_timesteps  | 68339    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 4584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1555     |\n",
      "|    total_timesteps  | 68878    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.76     |\n",
      "|    n_updates        | 4719     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1565     |\n",
      "|    total_timesteps  | 69365    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 4841     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1576     |\n",
      "|    total_timesteps  | 69922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 4980     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-131.26 +/- 12.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -131     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.684    |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1689     |\n",
      "|    total_timesteps  | 70495    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 5123     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1699     |\n",
      "|    total_timesteps  | 70971    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.815    |\n",
      "|    n_updates        | 5242     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1710     |\n",
      "|    total_timesteps  | 71539    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.82     |\n",
      "|    n_updates        | 5384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1719     |\n",
      "|    total_timesteps  | 71943    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 5485     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1730     |\n",
      "|    total_timesteps  | 72511    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.771    |\n",
      "|    n_updates        | 5627     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.653    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1743     |\n",
      "|    total_timesteps  | 73136    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.747    |\n",
      "|    n_updates        | 5783     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1758     |\n",
      "|    total_timesteps  | 73901    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.556    |\n",
      "|    n_updates        | 5975     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1769     |\n",
      "|    total_timesteps  | 74423    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 6105     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.645    |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1778     |\n",
      "|    total_timesteps  | 74833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.77     |\n",
      "|    n_updates        | 6208     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1791     |\n",
      "|    total_timesteps  | 75483    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 6370     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1801     |\n",
      "|    total_timesteps  | 75993    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.517    |\n",
      "|    n_updates        | 6498     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1812     |\n",
      "|    total_timesteps  | 76512    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 6627     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1824     |\n",
      "|    total_timesteps  | 77106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.526    |\n",
      "|    n_updates        | 6776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1835     |\n",
      "|    total_timesteps  | 77651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.62     |\n",
      "|    n_updates        | 6912     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1850     |\n",
      "|    total_timesteps  | 78372    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 7092     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1865     |\n",
      "|    total_timesteps  | 79127    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.821    |\n",
      "|    n_updates        | 7281     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1877     |\n",
      "|    total_timesteps  | 79682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.814    |\n",
      "|    n_updates        | 7420     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-113.96 +/- 17.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -114     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 10.1     |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1993     |\n",
      "|    total_timesteps  | 80394    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 7598     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2005     |\n",
      "|    total_timesteps  | 81000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 7749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2018     |\n",
      "|    total_timesteps  | 81628    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.816    |\n",
      "|    n_updates        | 7906     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2031     |\n",
      "|    total_timesteps  | 82260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 8064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2043     |\n",
      "|    total_timesteps  | 82876    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 8218     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2054     |\n",
      "|    total_timesteps  | 83408    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 8351     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2073     |\n",
      "|    total_timesteps  | 84332    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 8582     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2085     |\n",
      "|    total_timesteps  | 84934    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.539    |\n",
      "|    n_updates        | 8733     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2097     |\n",
      "|    total_timesteps  | 85520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.88     |\n",
      "|    n_updates        | 8879     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2109     |\n",
      "|    total_timesteps  | 86090    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.639    |\n",
      "|    n_updates        | 9022     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2120     |\n",
      "|    total_timesteps  | 86644    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.96     |\n",
      "|    n_updates        | 9160     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2153     |\n",
      "|    total_timesteps  | 88252    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.48     |\n",
      "|    n_updates        | 9562     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 2167     |\n",
      "|    total_timesteps  | 88947    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.926    |\n",
      "|    n_updates        | 9736     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 2181     |\n",
      "|    total_timesteps  | 89595    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 9898     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-145.94 +/- 22.31\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -146     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.846    |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2291     |\n",
      "|    total_timesteps  | 90055    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 10013    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2305     |\n",
      "|    total_timesteps  | 90730    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81     |\n",
      "|    n_updates        | 10182    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2325     |\n",
      "|    total_timesteps  | 91703    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.606    |\n",
      "|    n_updates        | 10425    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2338     |\n",
      "|    total_timesteps  | 92375    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.67     |\n",
      "|    n_updates        | 10593    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2363     |\n",
      "|    total_timesteps  | 93603    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.872    |\n",
      "|    n_updates        | 10900    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2382     |\n",
      "|    total_timesteps  | 94539    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.652    |\n",
      "|    n_updates        | 11134    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2407     |\n",
      "|    total_timesteps  | 95767    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.587    |\n",
      "|    n_updates        | 11441    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2418     |\n",
      "|    total_timesteps  | 96290    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.661    |\n",
      "|    n_updates        | 11572    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2426     |\n",
      "|    total_timesteps  | 96714    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 11678    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2438     |\n",
      "|    total_timesteps  | 97282    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.942    |\n",
      "|    n_updates        | 11820    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2451     |\n",
      "|    total_timesteps  | 97917    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.567    |\n",
      "|    n_updates        | 11979    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2470     |\n",
      "|    total_timesteps  | 98864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.512    |\n",
      "|    n_updates        | 12215    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 2486     |\n",
      "|    total_timesteps  | 99626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.449    |\n",
      "|    n_updates        | 12406    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-153.44 +/- 17.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -153     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2599     |\n",
      "|    total_timesteps  | 100221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.882    |\n",
      "|    n_updates        | 12555    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2631     |\n",
      "|    total_timesteps  | 101802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 12950    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2647     |\n",
      "|    total_timesteps  | 102600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 13149    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2663     |\n",
      "|    total_timesteps  | 103404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.491    |\n",
      "|    n_updates        | 13350    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2684     |\n",
      "|    total_timesteps  | 104412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.12     |\n",
      "|    n_updates        | 13602    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2699     |\n",
      "|    total_timesteps  | 105166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.31     |\n",
      "|    n_updates        | 13791    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2730     |\n",
      "|    total_timesteps  | 106675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.77     |\n",
      "|    n_updates        | 14168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2764     |\n",
      "|    total_timesteps  | 108338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.699    |\n",
      "|    n_updates        | 14584    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2789     |\n",
      "|    total_timesteps  | 109585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 14896    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-155.02 +/- 15.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -155     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.577    |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2909     |\n",
      "|    total_timesteps  | 110483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.14     |\n",
      "|    n_updates        | 15120    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2928     |\n",
      "|    total_timesteps  | 111410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.4      |\n",
      "|    n_updates        | 15352    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2949     |\n",
      "|    total_timesteps  | 112432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.721    |\n",
      "|    n_updates        | 15607    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2962     |\n",
      "|    total_timesteps  | 113052   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6        |\n",
      "|    n_updates        | 15762    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2978     |\n",
      "|    total_timesteps  | 113848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.9      |\n",
      "|    n_updates        | 15961    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 3044     |\n",
      "|    total_timesteps  | 117096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 16773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 3059     |\n",
      "|    total_timesteps  | 117810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 16952    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 3090     |\n",
      "|    total_timesteps  | 119337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.81     |\n",
      "|    n_updates        | 17334    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-168.23 +/- 24.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -168     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3225     |\n",
      "|    total_timesteps  | 120975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 17743    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3269     |\n",
      "|    total_timesteps  | 123162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.888    |\n",
      "|    n_updates        | 18290    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3307     |\n",
      "|    total_timesteps  | 125039   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 18759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3366     |\n",
      "|    total_timesteps  | 127941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 19485    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 3389     |\n",
      "|    total_timesteps  | 129045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.628    |\n",
      "|    n_updates        | 19761    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-162.41 +/- 17.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -162     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3551     |\n",
      "|    total_timesteps  | 132018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.331    |\n",
      "|    n_updates        | 20504    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3590     |\n",
      "|    total_timesteps  | 133925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.568    |\n",
      "|    n_updates        | 20981    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3670     |\n",
      "|    total_timesteps  | 137854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.06     |\n",
      "|    n_updates        | 21963    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-130.58 +/- 16.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -131     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.606    |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 3849     |\n",
      "|    total_timesteps  | 141690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.849    |\n",
      "|    n_updates        | 22922    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3914     |\n",
      "|    total_timesteps  | 144931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 23732    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 3995     |\n",
      "|    total_timesteps  | 148931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 24732    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-140.52 +/- 9.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -141     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.48     |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4170     |\n",
      "|    total_timesteps  | 152648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 25661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4250     |\n",
      "|    total_timesteps  | 156648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 26661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-153.08 +/- 22.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -153     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.237    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4432     |\n",
      "|    total_timesteps  | 160648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 27661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4513     |\n",
      "|    total_timesteps  | 164648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.6      |\n",
      "|    n_updates        | 28661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.199    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4594     |\n",
      "|    total_timesteps  | 168648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 29661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-117.21 +/- 22.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -117     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4776     |\n",
      "|    total_timesteps  | 172648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.623    |\n",
      "|    n_updates        | 30661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.161    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4856     |\n",
      "|    total_timesteps  | 176648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.362    |\n",
      "|    n_updates        | 31661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-142.83 +/- 17.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -143     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.581    |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5037     |\n",
      "|    total_timesteps  | 180648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 32661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.123    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 5118     |\n",
      "|    total_timesteps  | 184648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.548    |\n",
      "|    n_updates        | 33661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 5199     |\n",
      "|    total_timesteps  | 188648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 34661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-122.29 +/- 17.12\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -122     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0849   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5381     |\n",
      "|    total_timesteps  | 192648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 35661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0659   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 5461     |\n",
      "|    total_timesteps  | 196648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 36661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-135.13 +/- 28.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -135     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.19     |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5643     |\n",
      "|    total_timesteps  | 200648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.54     |\n",
      "|    n_updates        | 37661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5723     |\n",
      "|    total_timesteps  | 204648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.459    |\n",
      "|    n_updates        | 38661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5804     |\n",
      "|    total_timesteps  | 208648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.26     |\n",
      "|    n_updates        | 39661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-155.02 +/- 14.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -155     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 5986     |\n",
      "|    total_timesteps  | 212648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.31     |\n",
      "|    n_updates        | 40661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6066     |\n",
      "|    total_timesteps  | 216648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.529    |\n",
      "|    n_updates        | 41661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-136.68 +/- 65.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -137     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.64     |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6249     |\n",
      "|    total_timesteps  | 220648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.506    |\n",
      "|    n_updates        | 42661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6330     |\n",
      "|    total_timesteps  | 224648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.69     |\n",
      "|    n_updates        | 43661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6411     |\n",
      "|    total_timesteps  | 228648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.744    |\n",
      "|    n_updates        | 44661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-165.01 +/- 20.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -165     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6594     |\n",
      "|    total_timesteps  | 232648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.53     |\n",
      "|    n_updates        | 45661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6676     |\n",
      "|    total_timesteps  | 236648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.62     |\n",
      "|    n_updates        | 46661    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-137.19 +/- 72.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -137     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.472    |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6855     |\n",
      "|    total_timesteps  | 240457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 47614    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6928     |\n",
      "|    total_timesteps  | 244059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.466    |\n",
      "|    n_updates        | 48514    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 6999     |\n",
      "|    total_timesteps  | 247560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 49389    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-12.53 +/- 150.27\n",
      "Episode length: 922.40 +/- 135.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 922      |\n",
      "|    mean_reward      | -12.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7160     |\n",
      "|    total_timesteps  | 250903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.779    |\n",
      "|    n_updates        | 50225    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7236     |\n",
      "|    total_timesteps  | 254614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.508    |\n",
      "|    n_updates        | 51153    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7305     |\n",
      "|    total_timesteps  | 258032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.425    |\n",
      "|    n_updates        | 52007    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-67.60 +/- 51.39\n",
      "Episode length: 942.20 +/- 115.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 942      |\n",
      "|    mean_reward      | -67.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.494    |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7478     |\n",
      "|    total_timesteps  | 261821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.636    |\n",
      "|    n_updates        | 52955    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7559     |\n",
      "|    total_timesteps  | 265821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 53955    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7637     |\n",
      "|    total_timesteps  | 269664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34     |\n",
      "|    n_updates        | 54915    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-159.82 +/- 52.31\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -160     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 7819     |\n",
      "|    total_timesteps  | 273664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 55915    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7900     |\n",
      "|    total_timesteps  | 277664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.406    |\n",
      "|    n_updates        | 56915    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-119.17 +/- 38.08\n",
      "Episode length: 975.00 +/- 50.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 975      |\n",
      "|    mean_reward      | -119     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.771    |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 8079     |\n",
      "|    total_timesteps  | 281664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06     |\n",
      "|    n_updates        | 57915    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 8153     |\n",
      "|    total_timesteps  | 285355   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 58838    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8223     |\n",
      "|    total_timesteps  | 288813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 59703    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-171.08 +/- 62.05\n",
      "Episode length: 797.20 +/- 248.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 797      |\n",
      "|    mean_reward      | -171     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.05     |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 8371     |\n",
      "|    total_timesteps  | 292195   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.479    |\n",
      "|    n_updates        | 60548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8452     |\n",
      "|    total_timesteps  | 296190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 61547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8516     |\n",
      "|    total_timesteps  | 299387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 62346    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-131.47 +/- 44.16\n",
      "Episode length: 600.40 +/- 278.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -131     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 8623     |\n",
      "|    total_timesteps  | 301679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.527    |\n",
      "|    n_updates        | 62919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8694     |\n",
      "|    total_timesteps  | 305220   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 63804    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8744     |\n",
      "|    total_timesteps  | 307690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 64422    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-148.84 +/- 65.39\n",
      "Episode length: 477.80 +/- 225.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 478      |\n",
      "|    mean_reward      | -149     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.513    |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8849     |\n",
      "|    total_timesteps  | 310507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 65126    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8906     |\n",
      "|    total_timesteps  | 313312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 65827    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 8957     |\n",
      "|    total_timesteps  | 315856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 66463    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9024     |\n",
      "|    total_timesteps  | 319148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 67286    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-107.29 +/- 19.66\n",
      "Episode length: 862.20 +/- 275.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 862      |\n",
      "|    mean_reward      | -107     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.43     |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9167     |\n",
      "|    total_timesteps  | 321939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 67984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9239     |\n",
      "|    total_timesteps  | 325510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.94     |\n",
      "|    n_updates        | 68877    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9290     |\n",
      "|    total_timesteps  | 328015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.627    |\n",
      "|    n_updates        | 69503    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-122.24 +/- 36.42\n",
      "Episode length: 454.00 +/- 98.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 454      |\n",
      "|    mean_reward      | -122     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.454    |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9383     |\n",
      "|    total_timesteps  | 330389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.581    |\n",
      "|    n_updates        | 70097    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9433     |\n",
      "|    total_timesteps  | 332865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.35     |\n",
      "|    n_updates        | 70716    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9492     |\n",
      "|    total_timesteps  | 335763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 71440    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9533     |\n",
      "|    total_timesteps  | 337806   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 71951    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-84.89 +/- 21.15\n",
      "Episode length: 832.00 +/- 336.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 832      |\n",
      "|    mean_reward      | -84.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 14.4     |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9689     |\n",
      "|    total_timesteps  | 341379   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.575    |\n",
      "|    n_updates        | 72844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9721     |\n",
      "|    total_timesteps  | 342985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 73246    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9744     |\n",
      "|    total_timesteps  | 344136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.9      |\n",
      "|    n_updates        | 73533    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9801     |\n",
      "|    total_timesteps  | 346935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.453    |\n",
      "|    n_updates        | 74233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9842     |\n",
      "|    total_timesteps  | 348987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 74746    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-105.24 +/- 21.32\n",
      "Episode length: 761.80 +/- 293.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 762      |\n",
      "|    mean_reward      | -105     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.308    |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 9948     |\n",
      "|    total_timesteps  | 350399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 11       |\n",
      "|    n_updates        | 75099    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10006    |\n",
      "|    total_timesteps  | 353290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.38     |\n",
      "|    n_updates        | 75822    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10043    |\n",
      "|    total_timesteps  | 355106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 76276    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10089    |\n",
      "|    total_timesteps  | 357405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 76851    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-119.86 +/- 31.95\n",
      "Episode length: 348.00 +/- 126.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 348      |\n",
      "|    mean_reward      | -120     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10183    |\n",
      "|    total_timesteps  | 360326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.63     |\n",
      "|    n_updates        | 77581    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10225    |\n",
      "|    total_timesteps  | 362382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 78095    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10291    |\n",
      "|    total_timesteps  | 365679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.344    |\n",
      "|    n_updates        | 78919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10344    |\n",
      "|    total_timesteps  | 368319   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.704    |\n",
      "|    n_updates        | 79579    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-90.98 +/- 27.32\n",
      "Episode length: 880.40 +/- 239.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 880      |\n",
      "|    mean_reward      | -91      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.412    |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10495    |\n",
      "|    total_timesteps  | 371346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.42     |\n",
      "|    n_updates        | 80336    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10530    |\n",
      "|    total_timesteps  | 373059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.254    |\n",
      "|    n_updates        | 80764    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10589    |\n",
      "|    total_timesteps  | 376008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 81501    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10649    |\n",
      "|    total_timesteps  | 378960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 82239    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-99.19 +/- 52.30\n",
      "Episode length: 677.00 +/- 323.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 677      |\n",
      "|    mean_reward      | -99.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.671    |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10775    |\n",
      "|    total_timesteps  | 381746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 17.5     |\n",
      "|    n_updates        | 82936    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10830    |\n",
      "|    total_timesteps  | 384454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 83613    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10880    |\n",
      "|    total_timesteps  | 386901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.618    |\n",
      "|    n_updates        | 84225    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 10936    |\n",
      "|    total_timesteps  | 389720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.302    |\n",
      "|    n_updates        | 84929    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-97.98 +/- 62.34\n",
      "Episode length: 865.20 +/- 167.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 865      |\n",
      "|    mean_reward      | -98      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.357    |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11085    |\n",
      "|    total_timesteps  | 392785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.455    |\n",
      "|    n_updates        | 85696    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11141    |\n",
      "|    total_timesteps  | 395518   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.609    |\n",
      "|    n_updates        | 86379    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11168    |\n",
      "|    total_timesteps  | 396881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 86720    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-123.18 +/- 60.37\n",
      "Episode length: 573.40 +/- 338.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 573      |\n",
      "|    mean_reward      | -123     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11296    |\n",
      "|    total_timesteps  | 400375   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.458    |\n",
      "|    n_updates        | 87593    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11354    |\n",
      "|    total_timesteps  | 403229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 88307    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11381    |\n",
      "|    total_timesteps  | 404545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 88636    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11448    |\n",
      "|    total_timesteps  | 407902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 89475    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=26.72 +/- 130.41\n",
      "Episode length: 767.40 +/- 241.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 767      |\n",
      "|    mean_reward      | 26.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11595    |\n",
      "|    total_timesteps  | 411338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.569    |\n",
      "|    n_updates        | 90334    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11668    |\n",
      "|    total_timesteps  | 414961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.78     |\n",
      "|    n_updates        | 91240    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11737    |\n",
      "|    total_timesteps  | 418374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.927    |\n",
      "|    n_updates        | 92093    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-85.17 +/- 53.80\n",
      "Episode length: 840.20 +/- 228.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 840      |\n",
      "|    mean_reward      | -85.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11890    |\n",
      "|    total_timesteps  | 421750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.395    |\n",
      "|    n_updates        | 92937    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 11950    |\n",
      "|    total_timesteps  | 424765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.447    |\n",
      "|    n_updates        | 93691    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12029    |\n",
      "|    total_timesteps  | 428669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.488    |\n",
      "|    n_updates        | 94667    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-158.40 +/- 51.51\n",
      "Episode length: 755.80 +/- 223.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 756      |\n",
      "|    mean_reward      | -158     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.832    |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12157    |\n",
      "|    total_timesteps  | 431255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 14.3     |\n",
      "|    n_updates        | 95313    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12223    |\n",
      "|    total_timesteps  | 434497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 96124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12300    |\n",
      "|    total_timesteps  | 438325   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.774    |\n",
      "|    n_updates        | 97081    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-147.86 +/- 38.55\n",
      "Episode length: 730.60 +/- 219.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 731      |\n",
      "|    mean_reward      | -148     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12428    |\n",
      "|    total_timesteps  | 441024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.89     |\n",
      "|    n_updates        | 97755    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12509    |\n",
      "|    total_timesteps  | 445024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 98755    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12589    |\n",
      "|    total_timesteps  | 449024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 99755    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-51.94 +/- 47.86\n",
      "Episode length: 972.40 +/- 55.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 972      |\n",
      "|    mean_reward      | -51.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.343    |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12748    |\n",
      "|    total_timesteps  | 452038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.477    |\n",
      "|    n_updates        | 100509   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12829    |\n",
      "|    total_timesteps  | 456038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.48     |\n",
      "|    n_updates        | 101509   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 12899    |\n",
      "|    total_timesteps  | 459506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.449    |\n",
      "|    n_updates        | 102376   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-44.92 +/- 20.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -44.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13080    |\n",
      "|    total_timesteps  | 463506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 103376   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13160    |\n",
      "|    total_timesteps  | 467506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 104376   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-60.48 +/- 163.80\n",
      "Episode length: 523.20 +/- 201.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 523      |\n",
      "|    mean_reward      | -60.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 21.3     |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13279    |\n",
      "|    total_timesteps  | 470788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.486    |\n",
      "|    n_updates        | 105196   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13360    |\n",
      "|    total_timesteps  | 474788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 106196   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13421    |\n",
      "|    total_timesteps  | 477802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 106950   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-95.44 +/- 70.44\n",
      "Episode length: 878.40 +/- 211.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 878      |\n",
      "|    mean_reward      | -95.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.452    |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13580    |\n",
      "|    total_timesteps  | 481326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.49     |\n",
      "|    n_updates        | 107831   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13641    |\n",
      "|    total_timesteps  | 484322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 108580   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13701    |\n",
      "|    total_timesteps  | 487311   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.793    |\n",
      "|    n_updates        | 109327   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-63.58 +/- 25.56\n",
      "Episode length: 897.80 +/- 204.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 898      |\n",
      "|    mean_reward      | -63.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13848    |\n",
      "|    total_timesteps  | 490110   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 110027   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13908    |\n",
      "|    total_timesteps  | 493067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 110766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 13988    |\n",
      "|    total_timesteps  | 497067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 111766   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-30.86 +/- 13.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 18.4     |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14169    |\n",
      "|    total_timesteps  | 501067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.385    |\n",
      "|    n_updates        | 112766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14250    |\n",
      "|    total_timesteps  | 505067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.418    |\n",
      "|    n_updates        | 113766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14331    |\n",
      "|    total_timesteps  | 509067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 114766   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=47.27 +/- 101.15\n",
      "Episode length: 922.60 +/- 154.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 923      |\n",
      "|    mean_reward      | 47.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 510000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14487    |\n",
      "|    total_timesteps  | 512224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.663    |\n",
      "|    n_updates        | 115555   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14554    |\n",
      "|    total_timesteps  | 515541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 116385   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14635    |\n",
      "|    total_timesteps  | 519541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 117385   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-14.29 +/- 7.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 520000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.254    |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14816    |\n",
      "|    total_timesteps  | 523541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 118385   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 14897    |\n",
      "|    total_timesteps  | 527541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 119385   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-128.81 +/- 60.39\n",
      "Episode length: 560.00 +/- 273.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 560      |\n",
      "|    mean_reward      | -129     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 530000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.478    |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15019    |\n",
      "|    total_timesteps  | 530825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 120206   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15100    |\n",
      "|    total_timesteps  | 534825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 121206   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15168    |\n",
      "|    total_timesteps  | 538200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 122049   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-50.60 +/- 32.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -50.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 540000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15334    |\n",
      "|    total_timesteps  | 541438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 122859   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15415    |\n",
      "|    total_timesteps  | 545438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 123859   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15489    |\n",
      "|    total_timesteps  | 549126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.881    |\n",
      "|    n_updates        | 124781   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=-60.74 +/- 65.52\n",
      "Episode length: 838.20 +/- 296.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 838      |\n",
      "|    mean_reward      | -60.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15650    |\n",
      "|    total_timesteps  | 552894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.434    |\n",
      "|    n_updates        | 125723   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15712    |\n",
      "|    total_timesteps  | 555977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 126494   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15794    |\n",
      "|    total_timesteps  | 559977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 17.9     |\n",
      "|    n_updates        | 127494   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-57.79 +/- 68.72\n",
      "Episode length: 955.20 +/- 89.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 955      |\n",
      "|    mean_reward      | -57.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 560000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 127499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 15972    |\n",
      "|    total_timesteps  | 563977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 128494   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16053    |\n",
      "|    total_timesteps  | 567977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.504    |\n",
      "|    n_updates        | 129494   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-45.20 +/- 31.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -45.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 570000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 129999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16236    |\n",
      "|    total_timesteps  | 571977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.409    |\n",
      "|    n_updates        | 130494   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16317    |\n",
      "|    total_timesteps  | 575931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 131482   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16398    |\n",
      "|    total_timesteps  | 579931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.652    |\n",
      "|    n_updates        | 132482   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-43.69 +/- 56.77\n",
      "Episode length: 957.40 +/- 85.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 957      |\n",
      "|    mean_reward      | -43.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 580000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.465    |\n",
      "|    n_updates        | 132499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16568    |\n",
      "|    total_timesteps  | 583525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 133381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16650    |\n",
      "|    total_timesteps  | 587525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.451    |\n",
      "|    n_updates        | 134381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-20.20 +/- 25.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 590000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.869    |\n",
      "|    n_updates        | 134999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16833    |\n",
      "|    total_timesteps  | 591525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.86     |\n",
      "|    n_updates        | 135381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16914    |\n",
      "|    total_timesteps  | 595525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 136381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 16995    |\n",
      "|    total_timesteps  | 599525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.462    |\n",
      "|    n_updates        | 137381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-28.45 +/- 14.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.343    |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17178    |\n",
      "|    total_timesteps  | 603525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.812    |\n",
      "|    n_updates        | 138381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17260    |\n",
      "|    total_timesteps  | 607525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.589    |\n",
      "|    n_updates        | 139381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-36.74 +/- 4.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -36.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 610000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 139999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17443    |\n",
      "|    total_timesteps  | 611525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.486    |\n",
      "|    n_updates        | 140381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17524    |\n",
      "|    total_timesteps  | 615525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 141381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17605    |\n",
      "|    total_timesteps  | 619525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.566    |\n",
      "|    n_updates        | 142381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-18.71 +/- 7.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -18.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 620000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 142499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17788    |\n",
      "|    total_timesteps  | 623525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.592    |\n",
      "|    n_updates        | 143381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 17869    |\n",
      "|    total_timesteps  | 627525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 144381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-43.34 +/- 17.76\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -43.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 630000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 144999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 18052    |\n",
      "|    total_timesteps  | 631525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 145381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 18133    |\n",
      "|    total_timesteps  | 635525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 146381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 18214    |\n",
      "|    total_timesteps  | 639525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.572    |\n",
      "|    n_updates        | 147381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-11.71 +/- 28.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 640000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.688    |\n",
      "|    n_updates        | 147499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 18397    |\n",
      "|    total_timesteps  | 643525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.542    |\n",
      "|    n_updates        | 148381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 18478    |\n",
      "|    total_timesteps  | 647525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.913    |\n",
      "|    n_updates        | 149381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-31.82 +/- 23.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -31.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 18661    |\n",
      "|    total_timesteps  | 651525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.404    |\n",
      "|    n_updates        | 150381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 18742    |\n",
      "|    total_timesteps  | 655525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.575    |\n",
      "|    n_updates        | 151381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 18823    |\n",
      "|    total_timesteps  | 659525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 152381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-30.53 +/- 16.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 660000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.634    |\n",
      "|    n_updates        | 152499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19006    |\n",
      "|    total_timesteps  | 663525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.705    |\n",
      "|    n_updates        | 153381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19088    |\n",
      "|    total_timesteps  | 667525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 154381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-25.67 +/- 12.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -25.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 670000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 154999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19270    |\n",
      "|    total_timesteps  | 671525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.349    |\n",
      "|    n_updates        | 155381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19352    |\n",
      "|    total_timesteps  | 675525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.64     |\n",
      "|    n_updates        | 156381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19433    |\n",
      "|    total_timesteps  | 679525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 14.6     |\n",
      "|    n_updates        | 157381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-35.73 +/- 15.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -35.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 680000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 157499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19616    |\n",
      "|    total_timesteps  | 683525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.469    |\n",
      "|    n_updates        | 158381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19697    |\n",
      "|    total_timesteps  | 687525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12.9     |\n",
      "|    n_updates        | 159381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-30.84 +/- 13.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 690000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 159999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19880    |\n",
      "|    total_timesteps  | 691525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 160381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 19961    |\n",
      "|    total_timesteps  | 695525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 161381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20042    |\n",
      "|    total_timesteps  | 699525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.53     |\n",
      "|    n_updates        | 162381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-52.81 +/- 26.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -52.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.747    |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20225    |\n",
      "|    total_timesteps  | 703525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 163381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20307    |\n",
      "|    total_timesteps  | 707525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 164381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-45.06 +/- 16.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -45.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 710000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20490    |\n",
      "|    total_timesteps  | 711525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.576    |\n",
      "|    n_updates        | 165381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20571    |\n",
      "|    total_timesteps  | 715525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.502    |\n",
      "|    n_updates        | 166381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20652    |\n",
      "|    total_timesteps  | 719525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.412    |\n",
      "|    n_updates        | 167381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-35.96 +/- 29.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -36      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 720000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.55     |\n",
      "|    n_updates        | 167499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20835    |\n",
      "|    total_timesteps  | 723525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.594    |\n",
      "|    n_updates        | 168381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20916    |\n",
      "|    total_timesteps  | 727525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.401    |\n",
      "|    n_updates        | 169381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-25.69 +/- 25.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -25.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 730000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 169999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21099    |\n",
      "|    total_timesteps  | 731525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 170381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21180    |\n",
      "|    total_timesteps  | 735525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.519    |\n",
      "|    n_updates        | 171381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21261    |\n",
      "|    total_timesteps  | 739525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.607    |\n",
      "|    n_updates        | 172381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-36.97 +/- 18.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 740000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.453    |\n",
      "|    n_updates        | 172499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21444    |\n",
      "|    total_timesteps  | 743525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.449    |\n",
      "|    n_updates        | 173381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21526    |\n",
      "|    total_timesteps  | 747525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 174381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-43.24 +/- 15.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -43.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21709    |\n",
      "|    total_timesteps  | 751525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.374    |\n",
      "|    n_updates        | 175381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21790    |\n",
      "|    total_timesteps  | 755525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 176381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 21871    |\n",
      "|    total_timesteps  | 759525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 177381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-63.29 +/- 28.32\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -63.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 760000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 177499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22054    |\n",
      "|    total_timesteps  | 763525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.19     |\n",
      "|    n_updates        | 178381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22135    |\n",
      "|    total_timesteps  | 767525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 179381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-28.03 +/- 20.30\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 770000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 179999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22318    |\n",
      "|    total_timesteps  | 771525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.401    |\n",
      "|    n_updates        | 180381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22399    |\n",
      "|    total_timesteps  | 775525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 181381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22481    |\n",
      "|    total_timesteps  | 779525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 182381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-42.05 +/- 31.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -42.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 780000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 182499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22664    |\n",
      "|    total_timesteps  | 783525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.63     |\n",
      "|    n_updates        | 183381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22745    |\n",
      "|    total_timesteps  | 787525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.445    |\n",
      "|    n_updates        | 184381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-44.81 +/- 28.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -44.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 790000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.548    |\n",
      "|    n_updates        | 184999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 22927    |\n",
      "|    total_timesteps  | 791525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.571    |\n",
      "|    n_updates        | 185381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23009    |\n",
      "|    total_timesteps  | 795525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 186381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23090    |\n",
      "|    total_timesteps  | 799525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.532    |\n",
      "|    n_updates        | 187381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-53.47 +/- 21.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -53.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23273    |\n",
      "|    total_timesteps  | 803525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.49     |\n",
      "|    n_updates        | 188381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23354    |\n",
      "|    total_timesteps  | 807525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.523    |\n",
      "|    n_updates        | 189381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-60.29 +/- 17.98\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -60.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 810000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 189999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23537    |\n",
      "|    total_timesteps  | 811525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 190381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23618    |\n",
      "|    total_timesteps  | 815525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.608    |\n",
      "|    n_updates        | 191381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23699    |\n",
      "|    total_timesteps  | 819525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.397    |\n",
      "|    n_updates        | 192381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-28.86 +/- 30.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 820000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.516    |\n",
      "|    n_updates        | 192499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23882    |\n",
      "|    total_timesteps  | 823525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 193381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 23963    |\n",
      "|    total_timesteps  | 827525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.308    |\n",
      "|    n_updates        | 194381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-46.28 +/- 15.54\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -46.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 830000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.466    |\n",
      "|    n_updates        | 194999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24146    |\n",
      "|    total_timesteps  | 831525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.364    |\n",
      "|    n_updates        | 195381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24228    |\n",
      "|    total_timesteps  | 835525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 196381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24309    |\n",
      "|    total_timesteps  | 839525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 197381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-34.87 +/- 18.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -34.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 840000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 197499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24492    |\n",
      "|    total_timesteps  | 843525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.436    |\n",
      "|    n_updates        | 198381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24573    |\n",
      "|    total_timesteps  | 847525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 199381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-43.67 +/- 23.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -43.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.762    |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24756    |\n",
      "|    total_timesteps  | 851525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.351    |\n",
      "|    n_updates        | 200381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24837    |\n",
      "|    total_timesteps  | 855525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.619    |\n",
      "|    n_updates        | 201381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 24918    |\n",
      "|    total_timesteps  | 859525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 202381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-37.83 +/- 22.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 860000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 202499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25101    |\n",
      "|    total_timesteps  | 863525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.417    |\n",
      "|    n_updates        | 203381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25182    |\n",
      "|    total_timesteps  | 867525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.822    |\n",
      "|    n_updates        | 204381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-25.61 +/- 22.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -25.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 870000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 204999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25365    |\n",
      "|    total_timesteps  | 871525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.92     |\n",
      "|    n_updates        | 205381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25446    |\n",
      "|    total_timesteps  | 875525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 206381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25528    |\n",
      "|    total_timesteps  | 879525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.391    |\n",
      "|    n_updates        | 207381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-19.36 +/- 18.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 880000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 207499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25711    |\n",
      "|    total_timesteps  | 883525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.622    |\n",
      "|    n_updates        | 208381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25792    |\n",
      "|    total_timesteps  | 887525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.362    |\n",
      "|    n_updates        | 209381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-39.37 +/- 20.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -39.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 890000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 209999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 25975    |\n",
      "|    total_timesteps  | 891525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.512    |\n",
      "|    n_updates        | 210381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26056    |\n",
      "|    total_timesteps  | 895525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 211381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26137    |\n",
      "|    total_timesteps  | 899525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.518    |\n",
      "|    n_updates        | 212381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-33.54 +/- 25.91\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -33.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.451    |\n",
      "|    n_updates        | 212499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26320    |\n",
      "|    total_timesteps  | 903525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 213381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26401    |\n",
      "|    total_timesteps  | 907525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 214381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=-66.80 +/- 43.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -66.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 910000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.848    |\n",
      "|    n_updates        | 214999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26584    |\n",
      "|    total_timesteps  | 911525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.377    |\n",
      "|    n_updates        | 215381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26666    |\n",
      "|    total_timesteps  | 915525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 216381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26747    |\n",
      "|    total_timesteps  | 919525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 217381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-43.74 +/- 13.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -43.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 920000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.971    |\n",
      "|    n_updates        | 217499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 26930    |\n",
      "|    total_timesteps  | 923525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.432    |\n",
      "|    n_updates        | 218381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27011    |\n",
      "|    total_timesteps  | 927525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.412    |\n",
      "|    n_updates        | 219381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-32.91 +/- 41.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -32.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 930000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.473    |\n",
      "|    n_updates        | 219999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27194    |\n",
      "|    total_timesteps  | 931525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 220381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27275    |\n",
      "|    total_timesteps  | 935525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.61     |\n",
      "|    n_updates        | 221381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27356    |\n",
      "|    total_timesteps  | 939525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.791    |\n",
      "|    n_updates        | 222381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-19.52 +/- 27.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -19.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 940000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 222499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27539    |\n",
      "|    total_timesteps  | 943525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 223381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27620    |\n",
      "|    total_timesteps  | 947525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 224381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-24.25 +/- 21.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -24.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 224999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27803    |\n",
      "|    total_timesteps  | 951525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 225381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27884    |\n",
      "|    total_timesteps  | 955525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 226381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 27966    |\n",
      "|    total_timesteps  | 959525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 227381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=-63.93 +/- 16.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -63.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 960000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.354    |\n",
      "|    n_updates        | 227499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28149    |\n",
      "|    total_timesteps  | 963525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.686    |\n",
      "|    n_updates        | 228381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28230    |\n",
      "|    total_timesteps  | 967525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 229381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-42.41 +/- 9.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -42.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 970000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 229999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28412    |\n",
      "|    total_timesteps  | 971525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 230381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28494    |\n",
      "|    total_timesteps  | 975525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.31     |\n",
      "|    n_updates        | 231381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28575    |\n",
      "|    total_timesteps  | 979525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 232381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-41.96 +/- 22.34\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -42      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 980000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.467    |\n",
      "|    n_updates        | 232499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28758    |\n",
      "|    total_timesteps  | 983525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 233381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 28839    |\n",
      "|    total_timesteps  | 987525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 234381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-39.75 +/- 8.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -39.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 990000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.608    |\n",
      "|    n_updates        | 234999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29022    |\n",
      "|    total_timesteps  | 991525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.719    |\n",
      "|    n_updates        | 235381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29103    |\n",
      "|    total_timesteps  | 995525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.499    |\n",
      "|    n_updates        | 236381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29185    |\n",
      "|    total_timesteps  | 999525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.67     |\n",
      "|    n_updates        | 237381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-46.30 +/- 8.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -46.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 237499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29367    |\n",
      "|    total_timesteps  | 1003525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.328    |\n",
      "|    n_updates        | 238381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29449    |\n",
      "|    total_timesteps  | 1007525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 239381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-21.44 +/- 8.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -21.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.669    |\n",
      "|    n_updates        | 239999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29631    |\n",
      "|    total_timesteps  | 1011525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.375    |\n",
      "|    n_updates        | 240381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29713    |\n",
      "|    total_timesteps  | 1015525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.44     |\n",
      "|    n_updates        | 241381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29794    |\n",
      "|    total_timesteps  | 1019525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 242381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-80.76 +/- 40.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -80.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8      |\n",
      "|    n_updates        | 242499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 29977    |\n",
      "|    total_timesteps  | 1023525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.463    |\n",
      "|    n_updates        | 243381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30058    |\n",
      "|    total_timesteps  | 1027525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 244381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=-24.77 +/- 29.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -24.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 244999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30241    |\n",
      "|    total_timesteps  | 1031525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.374    |\n",
      "|    n_updates        | 245381   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30321    |\n",
      "|    total_timesteps  | 1035452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.319    |\n",
      "|    n_updates        | 246362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30402    |\n",
      "|    total_timesteps  | 1039452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 247362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-58.55 +/- 48.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -58.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.326    |\n",
      "|    n_updates        | 247499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30585    |\n",
      "|    total_timesteps  | 1043452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.483    |\n",
      "|    n_updates        | 248362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30666    |\n",
      "|    total_timesteps  | 1047452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.409    |\n",
      "|    n_updates        | 249362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-39.47 +/- 14.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -39.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 249999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30849    |\n",
      "|    total_timesteps  | 1051452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.636    |\n",
      "|    n_updates        | 250362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 30930    |\n",
      "|    total_timesteps  | 1055452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.277    |\n",
      "|    n_updates        | 251362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31012    |\n",
      "|    total_timesteps  | 1059452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.326    |\n",
      "|    n_updates        | 252362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=-50.51 +/- 26.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -50.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.501    |\n",
      "|    n_updates        | 252499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31194    |\n",
      "|    total_timesteps  | 1063452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.364    |\n",
      "|    n_updates        | 253362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31276    |\n",
      "|    total_timesteps  | 1067452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 254362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=-39.84 +/- 17.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -39.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 254999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31459    |\n",
      "|    total_timesteps  | 1071452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 255362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31540    |\n",
      "|    total_timesteps  | 1075452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.421    |\n",
      "|    n_updates        | 256362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31621    |\n",
      "|    total_timesteps  | 1079452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 257362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-52.55 +/- 13.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -52.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.423    |\n",
      "|    n_updates        | 257499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31804    |\n",
      "|    total_timesteps  | 1083452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 258362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 31885    |\n",
      "|    total_timesteps  | 1087452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 259362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=-22.35 +/- 29.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.322    |\n",
      "|    n_updates        | 259999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32068    |\n",
      "|    total_timesteps  | 1091452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 260362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32150    |\n",
      "|    total_timesteps  | 1095452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 261362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32231    |\n",
      "|    total_timesteps  | 1099452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 262362   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-34.25 +/- 25.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -34.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 262499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32414    |\n",
      "|    total_timesteps  | 1103452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 263362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32492    |\n",
      "|    total_timesteps  | 1107283  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.355    |\n",
      "|    n_updates        | 264320   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=21.66 +/- 79.92\n",
      "Episode length: 851.40 +/- 166.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 851      |\n",
      "|    mean_reward      | 21.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 264999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32658    |\n",
      "|    total_timesteps  | 1111178  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 265294   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32739    |\n",
      "|    total_timesteps  | 1115178  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 266294   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32812    |\n",
      "|    total_timesteps  | 1118779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 267194   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-18.07 +/- 19.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -18.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 267499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 32995    |\n",
      "|    total_timesteps  | 1122779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 268194   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33075    |\n",
      "|    total_timesteps  | 1126703  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.285    |\n",
      "|    n_updates        | 269175   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=-37.61 +/- 15.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 269999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 33258    |\n",
      "|    total_timesteps  | 1130703  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.311    |\n",
      "|    n_updates        | 270175   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33329    |\n",
      "|    total_timesteps  | 1134221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 271055   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33405    |\n",
      "|    total_timesteps  | 1137946  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 271986   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=-13.01 +/- 71.40\n",
      "Episode length: 948.60 +/- 66.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 949      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 272499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 33572    |\n",
      "|    total_timesteps  | 1141435  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 272858   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33642    |\n",
      "|    total_timesteps  | 1144872  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.297    |\n",
      "|    n_updates        | 273717   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33714    |\n",
      "|    total_timesteps  | 1148443  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.264    |\n",
      "|    n_updates        | 274610   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=16.54 +/- 71.61\n",
      "Episode length: 968.20 +/- 63.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 968      |\n",
      "|    mean_reward      | 16.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 274999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33893    |\n",
      "|    total_timesteps  | 1152426  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 275606   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 33958    |\n",
      "|    total_timesteps  | 1155587  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 276396   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34025    |\n",
      "|    total_timesteps  | 1158887  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 277221   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=122.83 +/- 23.31\n",
      "Episode length: 764.60 +/- 83.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 765      |\n",
      "|    mean_reward      | 123      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 277499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34184    |\n",
      "|    total_timesteps  | 1162887  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.296    |\n",
      "|    n_updates        | 278221   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34246    |\n",
      "|    total_timesteps  | 1165920  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 278979   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34317    |\n",
      "|    total_timesteps  | 1169449  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 279862   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-42.56 +/- 29.65\n",
      "Episode length: 917.80 +/- 164.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 918      |\n",
      "|    mean_reward      | -42.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 279999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34492    |\n",
      "|    total_timesteps  | 1173449  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 280862   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34559    |\n",
      "|    total_timesteps  | 1176775  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.897    |\n",
      "|    n_updates        | 281693   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=56.96 +/- 97.91\n",
      "Episode length: 851.20 +/- 200.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 851      |\n",
      "|    mean_reward      | 57       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 282499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 34717    |\n",
      "|    total_timesteps  | 1180258  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 282564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34787    |\n",
      "|    total_timesteps  | 1183714  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 283428   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 34865    |\n",
      "|    total_timesteps  | 1187546  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 284386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=6.89 +/- 68.01\n",
      "Episode length: 987.00 +/- 26.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 987      |\n",
      "|    mean_reward      | 6.89     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 284999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 35037    |\n",
      "|    total_timesteps  | 1191098  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.732    |\n",
      "|    n_updates        | 285274   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35100    |\n",
      "|    total_timesteps  | 1194213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.322    |\n",
      "|    n_updates        | 286053   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35175    |\n",
      "|    total_timesteps  | 1197909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.192    |\n",
      "|    n_updates        | 286977   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=-61.98 +/- 34.36\n",
      "Episode length: 948.00 +/- 104.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 948      |\n",
      "|    mean_reward      | -62      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 287499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 35331    |\n",
      "|    total_timesteps  | 1200828  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 287706   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35409    |\n",
      "|    total_timesteps  | 1204645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 288661   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35482    |\n",
      "|    total_timesteps  | 1208261  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 289565   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=100.96 +/- 78.58\n",
      "Episode length: 844.80 +/- 127.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 845      |\n",
      "|    mean_reward      | 101      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 289999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 35634    |\n",
      "|    total_timesteps  | 1211492  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 290372   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35715    |\n",
      "|    total_timesteps  | 1215492  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 291372   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 35789    |\n",
      "|    total_timesteps  | 1219159  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 292289   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=-16.25 +/- 17.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 292499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 35964    |\n",
      "|    total_timesteps  | 1222774  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 293193   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36032    |\n",
      "|    total_timesteps  | 1226096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 294023   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36085    |\n",
      "|    total_timesteps  | 1228723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 294680   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-28.74 +/- 16.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 294999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 36263    |\n",
      "|    total_timesteps  | 1232478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 295619   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36332    |\n",
      "|    total_timesteps  | 1235864  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 296465   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36401    |\n",
      "|    total_timesteps  | 1239240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 297309   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=5.31 +/- 70.34\n",
      "Episode length: 974.40 +/- 51.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 974      |\n",
      "|    mean_reward      | 5.31     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.877    |\n",
      "|    n_updates        | 297499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 36576    |\n",
      "|    total_timesteps  | 1242999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 298249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36651    |\n",
      "|    total_timesteps  | 1246674  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 299168   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=-40.50 +/- 8.54\n",
      "Episode length: 916.40 +/- 167.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 916      |\n",
      "|    mean_reward      | -40.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.276    |\n",
      "|    n_updates        | 299999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 36814    |\n",
      "|    total_timesteps  | 1250129  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 300032   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 36884    |\n",
      "|    total_timesteps  | 1253578  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 300894   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 36949    |\n",
      "|    total_timesteps  | 1256746  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 301686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=18.82 +/- 47.01\n",
      "Episode length: 994.00 +/- 12.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 994      |\n",
      "|    mean_reward      | 18.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 302499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37126    |\n",
      "|    total_timesteps  | 1260508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.393    |\n",
      "|    n_updates        | 302626   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37207    |\n",
      "|    total_timesteps  | 1264508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 303626   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 37288    |\n",
      "|    total_timesteps  | 1268508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 304626   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=0.09 +/- 88.12\n",
      "Episode length: 969.60 +/- 46.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 970      |\n",
      "|    mean_reward      | 0.0908   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 304999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37464    |\n",
      "|    total_timesteps  | 1272309  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 305577   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37541    |\n",
      "|    total_timesteps  | 1276073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 306518   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=-16.07 +/- 12.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 307499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37722    |\n",
      "|    total_timesteps  | 1280011  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 307502   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37804    |\n",
      "|    total_timesteps  | 1284011  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 308502   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 37879    |\n",
      "|    total_timesteps  | 1287727  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 309431   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=-42.12 +/- 42.58\n",
      "Episode length: 983.00 +/- 34.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 983      |\n",
      "|    mean_reward      | -42.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 309999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38060    |\n",
      "|    total_timesteps  | 1291727  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 310431   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38139    |\n",
      "|    total_timesteps  | 1295577  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 311394   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 38220    |\n",
      "|    total_timesteps  | 1299577  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.763    |\n",
      "|    n_updates        | 312394   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-18.38 +/- 12.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 312499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38399    |\n",
      "|    total_timesteps  | 1303420  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.254    |\n",
      "|    n_updates        | 313354   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38473    |\n",
      "|    total_timesteps  | 1307037  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 314259   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=-3.38 +/- 25.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.38    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 314999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38656    |\n",
      "|    total_timesteps  | 1311037  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 315259   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38717    |\n",
      "|    total_timesteps  | 1314060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 316014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38799    |\n",
      "|    total_timesteps  | 1318060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.328    |\n",
      "|    n_updates        | 317014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=0.19 +/- 24.89\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.188    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 317499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 38981    |\n",
      "|    total_timesteps  | 1322060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 318014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39063    |\n",
      "|    total_timesteps  | 1326060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 319014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-16.83 +/- 9.35\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 319999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39246    |\n",
      "|    total_timesteps  | 1330060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 320014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39327    |\n",
      "|    total_timesteps  | 1334060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.293    |\n",
      "|    n_updates        | 321014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39408    |\n",
      "|    total_timesteps  | 1338060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 322014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=-11.45 +/- 32.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 322499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39591    |\n",
      "|    total_timesteps  | 1342060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.181    |\n",
      "|    n_updates        | 323014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39673    |\n",
      "|    total_timesteps  | 1346060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 324014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=-7.06 +/- 22.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.06    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 324999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39855    |\n",
      "|    total_timesteps  | 1350060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 325014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 39937    |\n",
      "|    total_timesteps  | 1354060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 326014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40018    |\n",
      "|    total_timesteps  | 1358060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.207    |\n",
      "|    n_updates        | 327014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=1.44 +/- 33.17\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.44     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 327499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40201    |\n",
      "|    total_timesteps  | 1362060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 328014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40282    |\n",
      "|    total_timesteps  | 1366060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 329014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=-22.89 +/- 23.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 329999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40465    |\n",
      "|    total_timesteps  | 1370060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 330014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40546    |\n",
      "|    total_timesteps  | 1374060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 331014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40628    |\n",
      "|    total_timesteps  | 1378060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 332014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-14.19 +/- 17.91\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 332499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40810    |\n",
      "|    total_timesteps  | 1382060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 333014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 40892    |\n",
      "|    total_timesteps  | 1386060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 334014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=6.27 +/- 11.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 6.27     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 334999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41075    |\n",
      "|    total_timesteps  | 1390060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 335014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41156    |\n",
      "|    total_timesteps  | 1394060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 336014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41237    |\n",
      "|    total_timesteps  | 1398060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 337014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=6.43 +/- 12.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 6.43     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 337499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41420    |\n",
      "|    total_timesteps  | 1402060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 338014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41501    |\n",
      "|    total_timesteps  | 1406060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 339014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=-1.17 +/- 21.32\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.17    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 339999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41684    |\n",
      "|    total_timesteps  | 1410060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 340014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41765    |\n",
      "|    total_timesteps  | 1414060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 341014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 41846    |\n",
      "|    total_timesteps  | 1418060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 342014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=-12.61 +/- 8.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 342499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42029    |\n",
      "|    total_timesteps  | 1422060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 343014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42111    |\n",
      "|    total_timesteps  | 1426060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 344014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-6.40 +/- 16.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 344999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42294    |\n",
      "|    total_timesteps  | 1430060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 345014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42375    |\n",
      "|    total_timesteps  | 1434060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 346014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42456    |\n",
      "|    total_timesteps  | 1438060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 347014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-7.46 +/- 18.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.46    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 347499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42639    |\n",
      "|    total_timesteps  | 1442060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 348014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42720    |\n",
      "|    total_timesteps  | 1446060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 349014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=1.57 +/- 12.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.57     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 349999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42903    |\n",
      "|    total_timesteps  | 1450060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 350014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 42985    |\n",
      "|    total_timesteps  | 1454060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 351014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43066    |\n",
      "|    total_timesteps  | 1458060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 352014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-3.44 +/- 22.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.44    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 352499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43249    |\n",
      "|    total_timesteps  | 1462060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.293    |\n",
      "|    n_updates        | 353014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43330    |\n",
      "|    total_timesteps  | 1466060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 354014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=10.02 +/- 13.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 10       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 354999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43513    |\n",
      "|    total_timesteps  | 1470060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 355014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43577    |\n",
      "|    total_timesteps  | 1473200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 355799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43658    |\n",
      "|    total_timesteps  | 1477200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0889   |\n",
      "|    n_updates        | 356799   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=-12.85 +/- 25.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.197    |\n",
      "|    n_updates        | 357499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43841    |\n",
      "|    total_timesteps  | 1481200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 357799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 43922    |\n",
      "|    total_timesteps  | 1485200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 358799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44003    |\n",
      "|    total_timesteps  | 1489200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 359799   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=-5.34 +/- 25.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.34    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 359999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44186    |\n",
      "|    total_timesteps  | 1493200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0854   |\n",
      "|    n_updates        | 360799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44268    |\n",
      "|    total_timesteps  | 1497200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 361799   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=-7.56 +/- 24.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.56    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 362499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44445    |\n",
      "|    total_timesteps  | 1500909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 362727   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44524    |\n",
      "|    total_timesteps  | 1504799  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0919   |\n",
      "|    n_updates        | 363699   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44605    |\n",
      "|    total_timesteps  | 1508799  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 364699   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-16.61 +/- 22.97\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 364999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44783    |\n",
      "|    total_timesteps  | 1512573  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0892   |\n",
      "|    n_updates        | 365643   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 44864    |\n",
      "|    total_timesteps  | 1516573  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 366643   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=7.51 +/- 17.04\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 7.51     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 367499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45047    |\n",
      "|    total_timesteps  | 1520573  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 367643   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45123    |\n",
      "|    total_timesteps  | 1524288  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.742    |\n",
      "|    n_updates        | 368571   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45198    |\n",
      "|    total_timesteps  | 1527983  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 369495   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=-7.48 +/- 11.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.48    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 369999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45377    |\n",
      "|    total_timesteps  | 1531812  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.067    |\n",
      "|    n_updates        | 370452   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45455    |\n",
      "|    total_timesteps  | 1535644  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.357    |\n",
      "|    n_updates        | 371410   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45516    |\n",
      "|    total_timesteps  | 1538647  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 372161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-3.90 +/- 17.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.38     |\n",
      "|    n_updates        | 372499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45693    |\n",
      "|    total_timesteps  | 1542353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 373088   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45756    |\n",
      "|    total_timesteps  | 1545477  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 373869   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45836    |\n",
      "|    total_timesteps  | 1549404  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 374850   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=157.88 +/- 76.39\n",
      "Episode length: 635.00 +/- 194.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 635      |\n",
      "|    mean_reward      | 158      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 374999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 45963    |\n",
      "|    total_timesteps  | 1552466  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.087    |\n",
      "|    n_updates        | 375616   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46026    |\n",
      "|    total_timesteps  | 1555587  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0732   |\n",
      "|    n_updates        | 376396   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46088    |\n",
      "|    total_timesteps  | 1558599  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 377149   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=-4.23 +/- 18.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.23    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 377499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46257    |\n",
      "|    total_timesteps  | 1561939  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 377984   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46321    |\n",
      "|    total_timesteps  | 1565108  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 378776   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46388    |\n",
      "|    total_timesteps  | 1568381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 379595   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=3.58 +/- 14.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.58     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 379999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46553    |\n",
      "|    total_timesteps  | 1571502  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 380375   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46627    |\n",
      "|    total_timesteps  | 1575122  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 381280   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46704    |\n",
      "|    total_timesteps  | 1578919  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 382229   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=-14.13 +/- 12.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 382499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46872    |\n",
      "|    total_timesteps  | 1582197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 383049   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 46945    |\n",
      "|    total_timesteps  | 1585782  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 383945   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47021    |\n",
      "|    total_timesteps  | 1589507  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.082    |\n",
      "|    n_updates        | 384876   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=9.82 +/- 22.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 9.82     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 384999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47201    |\n",
      "|    total_timesteps  | 1593379  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 385844   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47279    |\n",
      "|    total_timesteps  | 1597221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0996   |\n",
      "|    n_updates        | 386805   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=3.05 +/- 8.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.05     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.391    |\n",
      "|    n_updates        | 387499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47462    |\n",
      "|    total_timesteps  | 1601221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 387805   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47543    |\n",
      "|    total_timesteps  | 1605221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0843   |\n",
      "|    n_updates        | 388805   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47625    |\n",
      "|    total_timesteps  | 1609221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 389805   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-4.61 +/- 9.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.61    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0681   |\n",
      "|    n_updates        | 389999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47802    |\n",
      "|    total_timesteps  | 1612962  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 390740   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 47877    |\n",
      "|    total_timesteps  | 1616668  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 391666   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=3.66 +/- 29.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.66     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 392499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48048    |\n",
      "|    total_timesteps  | 1620077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.475    |\n",
      "|    n_updates        | 392519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48130    |\n",
      "|    total_timesteps  | 1624077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 393519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48211    |\n",
      "|    total_timesteps  | 1628077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 394519   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-17.57 +/- 13.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 394999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48394    |\n",
      "|    total_timesteps  | 1632077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.351    |\n",
      "|    n_updates        | 395519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48475    |\n",
      "|    total_timesteps  | 1636077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 396519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48545    |\n",
      "|    total_timesteps  | 1639541  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 397385   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=6.80 +/- 19.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 397499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48720    |\n",
      "|    total_timesteps  | 1643156  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 398288   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48802    |\n",
      "|    total_timesteps  | 1647156  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 399288   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=14.58 +/- 15.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 14.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.611    |\n",
      "|    n_updates        | 399999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 48985    |\n",
      "|    total_timesteps  | 1651156  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0722   |\n",
      "|    n_updates        | 400288   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49062    |\n",
      "|    total_timesteps  | 1654954  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0925   |\n",
      "|    n_updates        | 401238   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49120    |\n",
      "|    total_timesteps  | 1657829  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 401957   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=98.34 +/- 90.60\n",
      "Episode length: 865.00 +/- 123.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 865      |\n",
      "|    mean_reward      | 98.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 402499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49264    |\n",
      "|    total_timesteps  | 1660560  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0743   |\n",
      "|    n_updates        | 402639   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49315    |\n",
      "|    total_timesteps  | 1663085  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.5      |\n",
      "|    n_updates        | 403271   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49355    |\n",
      "|    total_timesteps  | 1665073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 403768   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49395    |\n",
      "|    total_timesteps  | 1667009  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 404252   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49446    |\n",
      "|    total_timesteps  | 1669545  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 404886   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=53.37 +/- 54.78\n",
      "Episode length: 989.20 +/- 21.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 989      |\n",
      "|    mean_reward      | 53.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 404999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49594    |\n",
      "|    total_timesteps  | 1671842  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 405460   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49645    |\n",
      "|    total_timesteps  | 1674381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 406095   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49704    |\n",
      "|    total_timesteps  | 1677274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0946   |\n",
      "|    n_updates        | 406818   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=35.42 +/- 80.03\n",
      "Episode length: 901.80 +/- 196.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 902      |\n",
      "|    mean_reward      | 35.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 407499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49865    |\n",
      "|    total_timesteps  | 1680653  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 407663   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49906    |\n",
      "|    total_timesteps  | 1682692  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0962   |\n",
      "|    n_updates        | 408172   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49955    |\n",
      "|    total_timesteps  | 1685086  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 408771   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 49985    |\n",
      "|    total_timesteps  | 1686588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 409146   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50020    |\n",
      "|    total_timesteps  | 1688283  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 409570   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=62.11 +/- 82.66\n",
      "Episode length: 899.40 +/- 201.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 899      |\n",
      "|    mean_reward      | 62.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 409999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50164    |\n",
      "|    total_timesteps  | 1690861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 410215   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50211    |\n",
      "|    total_timesteps  | 1693199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.926    |\n",
      "|    n_updates        | 410799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50246    |\n",
      "|    total_timesteps  | 1694903  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 411225   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50280    |\n",
      "|    total_timesteps  | 1696558  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 411639   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 50339    |\n",
      "|    total_timesteps  | 1699477  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 412369   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=233.50 +/- 29.23\n",
      "Episode length: 490.60 +/- 229.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 491      |\n",
      "|    mean_reward      | 233      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 412499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 233.50  is above the threshold 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f06cf02bee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =DQN(\"MlpPolicy\",env,verbose=1) \n",
    "model.learn(total_timesteps=2000000, callback = evalcallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f049c5e-f7d5-471d-b339-b953d4668357",
   "metadata": {},
   "source": [
    "# 6. Saving and loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6595be-0184-40d5-9af4-caf2e1383e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(DQN_path) \n",
    "model = DQN.load(DQN_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ccfc8-f1b5-4c3c-8500-75897830e711",
   "metadata": {},
   "source": [
    "# 7. Evalutating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79501c9-6c4c-4f56-a250-aee9dae3ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179.04574527594502, 94.48759777235604)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env,n_eval_episodes = 10, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fccb7-10da-441d-970f-3b07017a0117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
